{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Helper function to parse the tripod sequence file\n",
    "def parse_tripod_seq_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        image_dims = list(map(int, lines[0].split()))\n",
    "        num_frames = list(map(int, lines[1].split()))\n",
    "        frames_360 = list(map(int, lines[4].split()))\n",
    "        frontal_frames = list(map(int, lines[5].split()))\n",
    "        rotation_sense = list(map(int, lines[6].split()))\n",
    "    return image_dims, num_frames, frames_360, frontal_frames, rotation_sense\n",
    "\n",
    "\n",
    "# Function to load and resize an image using PIL\n",
    "def load_and_resize_image(filename, img_height, img_width):\n",
    "    # Open the image file\n",
    "    img = Image.open(filename)\n",
    "    # Resize the image\n",
    "    img = img.resize((img_width, img_height))\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = np.array(img)\n",
    "    return img_array\n",
    "\n",
    "\n",
    "# Function to load and preprocess image and bbox data\n",
    "def load_and_preprocess_data(base_path, sequence_ids, img_width, img_height,\n",
    "                             frames_per_seq, frames_360, frontal_frames, rotation_sense):\n",
    "    data = []\n",
    "    labels = []\n",
    "    bboxes = []\n",
    "\n",
    "    for i, seq_id in enumerate(tqdm(sequence_ids, desc='Loading sequences')):\n",
    "        num_frames = frames_per_seq[i]\n",
    "        num_frames_360 = frames_360[i]\n",
    "        frontal_frame = frontal_frames[i]\n",
    "        sense = rotation_sense[i]\n",
    "        bbox_path = f\"{base_path}/bbox_{seq_id:02d}.txt\"\n",
    "        bbox_data = np.loadtxt(bbox_path, delimiter=' ')\n",
    "\n",
    "        # for frame_id in tqdm(range(1, num_frames + 1), desc=f'Processing seq {seq_id}', leave=False):\n",
    "        for frame_id in range(1, num_frames + 1):\n",
    "            filename = f\"{base_path}/tripod_seq_{seq_id:02d}_{frame_id:03d}.jpg\"\n",
    "\n",
    "            img = load_and_resize_image(filename, img_height, img_width)\n",
    "\n",
    "            # img /= 255.0  # Normalize to [0, 1]\n",
    "\n",
    "            relative_position = (frame_id - frontal_frame) % num_frames_360\n",
    "            rotation_angle = relative_position * (360 / num_frames_360) * sense\n",
    "\n",
    "            data.append(img)\n",
    "            labels.append(rotation_angle)\n",
    "            bboxes.append(bbox_data[frame_id - 1])  # Add bbox data\n",
    "\n",
    "    return np.array(data), np.array(labels), np.array(bboxes)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    file_path = r'./data/epfl-gims08/tripod-seq/tripod-seq.txt'\n",
    "    base_path = r'./data/epfl-gims08/tripod-seq'\n",
    "    train_sequence_ids = list(range(1, 11))  # Sequences 1-10 for training\n",
    "    test_sequence_ids = list(range(11, 21))  # Sequences 11-20 for testing\n",
    "\n",
    "    image_dims, num_frames, frames_360, frontal_frames, rotation_sense = parse_tripod_seq_file(file_path)\n",
    "    img_width, img_height = image_dims[1], image_dims[2]\n",
    "\n",
    "    # Load data\n",
    "    train_images, train_labels, train_bboxes = load_and_preprocess_data(\n",
    "        base_path, train_sequence_ids, img_width, img_height, num_frames[:10], frames_360[:10], frontal_frames[:10],\n",
    "        rotation_sense[:10])\n",
    "    test_images, test_labels, test_bboxes = load_and_preprocess_data(\n",
    "        base_path, test_sequence_ids, img_width, img_height, num_frames[10:], frames_360[10:], frontal_frames[10:],\n",
    "        rotation_sense[10:])\n",
    "\n",
    "    return train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import load_data\n",
    "\n",
    "\n",
    "class VehicleDataset(Dataset):\n",
    "    def __init__(self, images, labels, bboxes):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.bboxes = bboxes\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx])\n",
    "        label = self.labels[idx]\n",
    "        bbox = self.bboxes[idx]\n",
    "        cropped_image = image.crop((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]))\n",
    "        image_tensor = self.transforms(cropped_image)\n",
    "        return image_tensor, torch.tensor([label])\n",
    "\n",
    "\n",
    "class AnglePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AnglePredictor, self).__init__()\n",
    "        self.resnet_model = models.resnet50(pretrained=True)\n",
    "        self.resnet_model = nn.Sequential(*list(self.resnet_model.children())[:-1])\n",
    "        self.regression_head = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        features = self.resnet_model(pixel_values)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        angle = self.regression_head(features)\n",
    "        return angle\n",
    "\n",
    "\n",
    "def get_data_loaders(train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes, batch_size=4):\n",
    "    train_dataset = VehicleDataset(train_images, train_labels, train_bboxes)\n",
    "    test_dataset = VehicleDataset(test_images, test_labels, test_bboxes)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.L1Loss()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            total_loss += loss.item()\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {average_loss}\")\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "        evaluate(model, test_loader, device)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--bz\", default=4, type=int, help=\"batch size\")\n",
    "    # parser.add_argument(\"--epoch\", default=100, type=int)\n",
    "    #\n",
    "    # args = parser.parse_args()\n",
    "    # print(args)\n",
    "\n",
    "    bz = 4\n",
    "    epoch = 100\n",
    "\n",
    "    train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes = load_data.load_data()\n",
    "    train_loader, test_loader = get_data_loaders(\n",
    "        train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes, bz,\n",
    "    )\n",
    "\n",
    "    model = AnglePredictor()\n",
    "    train_model(model, train_loader, test_loader, num_epochs=epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sequences: 100%|██████████| 10/10 [00:01<00:00,  5.12it/s]\n",
      "Loading sequences: 100%|██████████| 10/10 [00:03<00:00,  2.70it/s]\n",
      "C:\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m    108\u001B[0m train_loader, test_loader \u001B[38;5;241m=\u001B[39m get_data_loaders(\n\u001B[0;32m    109\u001B[0m     train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes, bz,\n\u001B[0;32m    110\u001B[0m )\n\u001B[0;32m    112\u001B[0m model \u001B[38;5;241m=\u001B[39m AnglePredictor()\n\u001B[1;32m--> 113\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, test_loader, num_epochs)\u001B[0m\n\u001B[0;32m     87\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[0;32m     88\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 89\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     90\u001B[0m     running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrunning_loss\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\anaconda\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32mC:\\anaconda\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[1;32mC:\\anaconda\\lib\\site-packages\\torch\\optim\\adam.py:132\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    129\u001B[0m     state_steps \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    130\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m--> 132\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_group\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    141\u001B[0m     adam(\n\u001B[0;32m    142\u001B[0m         params_with_grad,\n\u001B[0;32m    143\u001B[0m         grads,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    160\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    161\u001B[0m     )\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32mC:\\anaconda\\lib\\site-packages\\torch\\optim\\adam.py:92\u001B[0m, in \u001B[0;36mAdam._init_group\u001B[1;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001B[0m\n\u001B[0;32m     86\u001B[0m state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     87\u001B[0m     torch\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m1\u001B[39m,), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat, device\u001B[38;5;241m=\u001B[39mp\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;241m0.\u001B[39m)\n\u001B[0;32m     90\u001B[0m )\n\u001B[0;32m     91\u001B[0m \u001B[38;5;66;03m# Exponential moving average of gradient values\u001B[39;00m\n\u001B[1;32m---> 92\u001B[0m state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexp_avg\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreserve_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;66;03m# Exponential moving average of squared gradient values\u001B[39;00m\n\u001B[0;32m     94\u001B[0m state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexp_avg_sq\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros_like(p, memory_format\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mpreserve_format)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T07:18:54.732623500Z",
     "start_time": "2024-04-22T07:18:54.729114600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Helper function to parse the tripod sequence file\n",
    "def parse_tripod_seq_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        image_dims = list(map(int, lines[0].split()))\n",
    "        num_frames = list(map(int, lines[1].split()))\n",
    "        frames_360 = list(map(int, lines[4].split()))\n",
    "        frontal_frames = list(map(int, lines[5].split()))\n",
    "        rotation_sense = list(map(int, lines[6].split()))\n",
    "    return image_dims, num_frames, frames_360, frontal_frames, rotation_sense\n",
    "\n",
    "\n",
    "# Function to load and resize an image using PIL\n",
    "def load_and_resize_image(filename, img_height, img_width):\n",
    "    # Open the image file\n",
    "    img = Image.open(filename)\n",
    "    # Resize the image\n",
    "    img = img.resize((img_width, img_height))\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = np.array(img)\n",
    "    return img_array\n",
    "\n",
    "\n",
    "# Function to load and preprocess image and bbox data\n",
    "def load_and_preprocess_data(base_path, sequence_ids, img_width, img_height,\n",
    "                             frames_per_seq, frames_360, frontal_frames, rotation_sense):\n",
    "    data = []\n",
    "    labels = []\n",
    "    bboxes = []\n",
    "\n",
    "    for i, seq_id in enumerate(tqdm(sequence_ids, desc='Loading sequences')):\n",
    "        num_frames = frames_per_seq[i]\n",
    "        num_frames_360 = frames_360[i]\n",
    "        frontal_frame = frontal_frames[i]\n",
    "        sense = rotation_sense[i]\n",
    "        bbox_path = f\"{base_path}/bbox_{seq_id:02d}.txt\"\n",
    "        bbox_data = np.loadtxt(bbox_path, delimiter=' ')\n",
    "\n",
    "        # for frame_id in tqdm(range(1, num_frames + 1), desc=f'Processing seq {seq_id}', leave=False):\n",
    "        for frame_id in range(1, num_frames + 1):\n",
    "            filename = f\"{base_path}/tripod_seq_{seq_id:02d}_{frame_id:03d}.jpg\"\n",
    "\n",
    "            img = load_and_resize_image(filename, img_height, img_width)\n",
    "\n",
    "            # img /= 255.0  # Normalize to [0, 1]\n",
    "\n",
    "            relative_position = (frame_id - frontal_frame) % num_frames_360\n",
    "            rotation_angle = relative_position * (360 / num_frames_360) * sense\n",
    "\n",
    "            data.append(img)\n",
    "            labels.append(rotation_angle)\n",
    "            bboxes.append(bbox_data[frame_id - 1])  # Add bbox data\n",
    "\n",
    "    return np.array(data), np.array(labels), np.array(bboxes)\n",
    "\n",
    "\n",
    "def map_angle_to_0_360(angle):\n",
    "    return angle % 360\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    file_path = r'./data/epfl-gims08/tripod-seq/tripod-seq.txt'\n",
    "    base_path = r'./data/epfl-gims08/tripod-seq'\n",
    "    train_sequence_ids = list(range(1, 11))  # Sequences 1-10 for training\n",
    "    test_sequence_ids = list(range(11, 21))  # Sequences 11-20 for testing\n",
    "\n",
    "    image_dims, num_frames, frames_360, frontal_frames, rotation_sense = parse_tripod_seq_file(file_path)\n",
    "    img_width, img_height = image_dims[1], image_dims[2]\n",
    "\n",
    "    # Load data\n",
    "    train_images, train_labels, train_bboxes = load_and_preprocess_data(\n",
    "        base_path, train_sequence_ids, img_width, img_height, num_frames[:10], frames_360[:10], frontal_frames[:10],\n",
    "        rotation_sense[:10])\n",
    "    test_images, test_labels, test_bboxes = load_and_preprocess_data(\n",
    "        base_path, test_sequence_ids, img_width, img_height, num_frames[10:], frames_360[10:], frontal_frames[10:],\n",
    "        rotation_sense[10:])\n",
    "    \n",
    "    train_labels = [map_angle_to_0_360(angle) for angle in train_labels]\n",
    "    test_labels = [map_angle_to_0_360(angle) for angle in test_labels]\n",
    "\n",
    "    return train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import load_data\n",
    "\n",
    "\n",
    "class VehicleDataset(Dataset):\n",
    "    def __init__(self, images, labels, bboxes):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.bboxes = bboxes\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx])\n",
    "        label = self.labels[idx]\n",
    "        bbox = self.bboxes[idx]\n",
    "        cropped_image = image.crop((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]))\n",
    "        image_tensor = self.transforms(cropped_image)\n",
    "        return image_tensor, torch.tensor([label])\n",
    "\n",
    "\n",
    "class AnglePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AnglePredictor, self).__init__()\n",
    "        self.resnet_model = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Freeze all layers first\n",
    "        for param in self.resnet_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze the last 15 layers\n",
    "        num_layers = len(list(self.resnet_model.children()))\n",
    "        layers_to_unfreeze = list(self.resnet_model.children())[num_layers - 15:]\n",
    "        for layer in layers_to_unfreeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # Modify the ResNet model to not include the final fully connected layer\n",
    "        self.features = nn.Sequential(*list(self.resnet_model.children())[:-1])\n",
    "\n",
    "        # Expanded regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1)  # Outputting a single value for angle\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        features = self.features(pixel_values)\n",
    "        angle = self.regression_head(features)\n",
    "        return angle\n",
    "\n",
    "\n",
    "def get_data_loaders(train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes, batch_size=4):\n",
    "    train_dataset = VehicleDataset(train_images, train_labels, train_bboxes)\n",
    "    test_dataset = VehicleDataset(test_images, test_labels, test_bboxes)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.L1Loss()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            total_loss += loss.item()\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {average_loss}\")\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "        evaluate(model, test_loader, device)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--bz\", default=4, type=int, help=\"batch size\")\n",
    "    # parser.add_argument(\"--epoch\", default=100, type=int)\n",
    "    #\n",
    "    # args = parser.parse_args()\n",
    "    # print(args)\n",
    "\n",
    "    bz = 4\n",
    "    epoch = 30\n",
    "\n",
    "    train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes = load_data.load_data()\n",
    "    train_loader, test_loader = get_data_loaders(\n",
    "        train_images, train_labels, train_bboxes, test_images, test_labels, test_bboxes, bz,\n",
    "    )\n",
    "\n",
    "    model = AnglePredictor()\n",
    "    train_model(model, train_loader, test_loader, num_epochs=epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T07:18:54.744845900Z",
     "start_time": "2024-04-22T07:18:54.730622300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sequences: 100%|██████████| 10/10 [00:02<00:00,  4.04it/s]\n",
      "Loading sequences: 100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n",
      "C:\\Users\\liubyfly\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\liubyfly\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6974.360015713966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:15<07:42, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 59.117274958746776\n",
      "Epoch 2, Loss: 5021.028327321198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:26<06:01, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 54.33486444268908\n",
      "Epoch 3, Loss: 3477.4082488496424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:40<06:04, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 47.92814289842333\n",
      "Epoch 4, Loss: 3284.282176816261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:51<05:22, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 51.496084986414225\n",
      "Epoch 5, Loss: 2689.7687944056624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [01:04<05:10, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 47.77960257530212\n",
      "Epoch 6, Loss: 2148.249236759897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [01:21<05:36, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 55.63437574931553\n",
      "Epoch 7, Loss: 1686.4527199276422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [01:37<05:36, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 52.83587896823883\n",
      "Epoch 8, Loss: 2136.594041888997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [01:52<05:29, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 46.92001065186092\n",
      "Epoch 9, Loss: 2139.6221013085315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [02:09<05:23, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 49.78110225881849\n",
      "Epoch 10, Loss: 1387.9519858408783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [02:26<05:18, 15.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 57.80732863289969\n",
      "Epoch 11, Loss: 1496.9738524873378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [02:42<05:04, 16.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 48.60942623274667\n",
      "Epoch 12, Loss: 933.9934881622509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [02:59<04:50, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 50.19071375642504\n",
      "Epoch 13, Loss: 875.7337358684863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [03:15<04:36, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 46.5194636123521\n",
      "Epoch 14, Loss: 884.1041913889222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [03:29<04:10, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 44.59114382352148\n",
      "Epoch 15, Loss: 798.3635876348463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [03:41<03:36, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 47.65998021619661\n",
      "Epoch 16, Loss: 856.9130673036736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [03:57<03:29, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 49.56666464975902\n",
      "Epoch 17, Loss: 783.6413563291906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [04:10<03:08, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 45.35184080260141\n",
      "Epoch 18, Loss: 680.1430963807187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [04:21<02:40, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 45.15794289963586\n",
      "Epoch 19, Loss: 871.705000977597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [04:33<02:20, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 47.27036942243576\n",
      "Epoch 20, Loss: 854.5469924215543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [04:48<02:13, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 47.091832340615134\n",
      "Epoch 21, Loss: 865.4591229844901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [04:58<01:53, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 46.33852631705148\n",
      "Epoch 22, Loss: 888.3969518887794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [05:09<01:36, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 45.64767815555845\n",
      "Epoch 23, Loss: 814.7963433896081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [05:23<01:28, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 46.26126361489296\n",
      "Epoch 24, Loss: 715.2617471921242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [05:39<01:21, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 45.30663699422564\n",
      "Epoch 25, Loss: 550.1137787867401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [05:55<01:11, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 46.579953144277845\n",
      "Epoch 26, Loss: 542.3718723782039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [06:11<00:58, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 42.935851386615205\n",
      "Epoch 27, Loss: 783.3600385504254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [06:27<00:45, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 45.63759851029941\n",
      "Epoch 28, Loss: 584.7962400210106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [06:45<00:31, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 41.27066947051457\n",
      "Epoch 29, Loss: 623.5585474887137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [07:01<00:15, 15.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 43.14339837857655\n",
      "Epoch 30, Loss: 518.1580571174621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [07:17<00:00, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 47.302770141192845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T07:26:20.296603Z",
     "start_time": "2024-04-22T07:18:54.739845100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T07:26:20.299680900Z",
     "start_time": "2024-04-22T07:26:20.297607500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
